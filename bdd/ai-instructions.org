* Introduction
This org-mode document contains instructions for an ai agent to assist in my workflow, which is oriented around behavior-driven development. Tasks we will be performing:
- generating user stories from text that contains natural-language brainstorming about desired system behavior
- generating new BDD Features in order to fulfill user stories
- adjusting existing BDD Features in order to fulfill user stories
- generating Scenarios for Features
- generating Step Definitions for cenarios

All Features and Scenarios will be written in the Gherkin language used by Cucumber. Step Definitions may be written in a variety of languages, and whichever language I choose, I will provide language-specific instructions for generating Step Definitions.

Each other top-level subtree in this org-mode document contains instructions for how to help with a specific task. When performing a task, just give me the output without explanation; if I have questions, I will ask. Also, when generating Features, Scenarios, Step Definitions, file names, descriptive text, and tags, prefer to be succinct and terse rather than wordy.

For further information on the principles and practices I am using, and which should guide you in your tasks as well, see:
- the entirety of the https://cucumber.io/ site
- https://cucumber.io/docs/gherkin/reference
- https://cucumber.io/docs/bdd/better-gherkin
- https://github.com/andredesousa/gherkin-best-practices
- http://www.thinkcode.se/blog/2016/06/22/cucumber-antipatterns

* Generating user stories
I will provide you with what I refer to as "ideas" - unstructured text that contains natural-language brainstorming about desired system behavior. I may also suggest an organization scheme with which to categorize user stories.

Each user story should be centered around a single behavior as experienced from the user's perspective and should follow the general pattern "As a <role>, I want <system capability>, so that <benefit>."

User stories should have the following characteristics:

- Independent: The story should stand alone, with minimal dependencies on other stories, allowing it to be developed, tested, and delivered independently.
- Negotiable: The story should be a starting point for discussion, not a rigid contract. It should allow for collaboration between stakeholders, developers, and testers to refine details.
- Valuable: The story should deliver clear value to the user or stakeholder, focusing on the "why" (benefit) to ensure it aligns with user needs or business goals.
- Estimable: The story should be clear enough for the team to estimate the effort required to implement it, even if the estimate is rough initially.
- Small: The story should be concise and focused, small enough to be completed within a single iteration or sprint, enabling quick delivery and feedback.
- Testable: The story should have clear acceptance criteria that can be translated into testable scenarios (e.g., Gherkin scenarios in BDD), ensuring the behavior can be verified.

From the provided informal "ideas", generate user stories in one of the formats described in a subtree below. Generate as many user stories as seems necessary to represent all the content in "ideas".

** Generating user stories in org-mode format
For each user story, use the following template (enclosed in quotes):
"* future <story title> <story tags>
:PROPERTIES:
:ID: >id<
:CATEGORY: task
:EFFORT_TYPE: work
:FREQUENCY: once
:HAS_DUE_DATE: 
:EFFORT_AMOUNT: average
:BUDGET_IMPACT: trivial
:COMMITMENT: probably
:HARD_DATE_DEPENDENCY: no
:SOFT_DATE_DEPENDENCY: no
:HARD_INTERNAL_DEPENDENCY: no
:SOFT_INTERNAL_DEPENDENCY: no
:HARD_EXTERNAL_DEPENDENCY: no
:SOFT_EXTERNAL_DEPENDENCY: no
:EFFORT: 0d
:ESTIMATED_COST: 0
:ACTUAL_EFFORT: 
:ACTUAL_COST: 
:END:

<story content>

<story notes>

"

Generated user stories should reproduce the template verbatim except for the enclosing quotation marks and the content marked by angle brackets:
- <story title> should be replaced with a short title that succinctly represents the story's desired system capability. Be terse; it doesn't have to fully describe the capability.
- <story tags> should be replaced with a set of org-mode tags that categorize the story, potentially by multiple kinds of categorization. For example, a story might be categorized by both role and system component, thus having the tags ":customer:login_screen:". If I have suggested an organizational scheme, use that for categorization. Otherwise, try to categorize both by role and system component. However, don't generate story tags if there are less than a dozen user stories or the system is small and simple; in that case categorization won't be very useful. If there are story tags, make sure they are separated by colons, that there is a colon at the beginning and the end of the list of tags, and that individual tags are underscore-separated if they contain multiple words. For example: ":tag_1:tag_2:etc:".
- <story content> should be the text of the story according to the general pattern "As a <role>, I want <system capability>, so that <benefit>", although it could be expanded as necessary. Each phrase should be on a different line.
- <story notes> should be replaced with any relevant notes or ideas that are associated with the story and are not already captured in the <story content>
- note that i will replace the text ">id<" so you can ignore it
- The final output should be an org-mode file where each user story is a top-level headline.

* Generating or adjusting feature files
I will provide org-mode files that contain user stories as top-level subtrees, in the format described in the section "Generating user stories in org-mode format". Note that each top-level headline begins with an asterisk and then a todo keyword, either "future", "next", "now", or "past". I also might provide existing Gherkin feature files.

The result of this task should be a set of Gherkin feature files that fully satisfy all the user stories in the stories files that are marked with the "now" keyword. By "fully satisfy all the user stories", I mean that the resulting set of feature files should in some way describe and make testable all the desired system capabilities contained within the relevant user stories.

Gherkin feature files primarily contain Features and associated Scenarios. Features should describe a single system capability, and associated Scenarios should be concrete, testable examples of that Feature. Note that user stories might not map one-to-one to Features. One user story might indicate multiple Features that need to be represented in the feature files, or multiple stories might all be related to a single Feature.

Features should be small and specific enough that they don't require multiple dozens of Scenarios to describe, but general enough that they need more than a few Scenarios to describe. Generally, a feature should look like this (enclosed in quotes):
"  Feature: <title>
    <narrative section>

    Background:
      <shared context>
      
    <scenarios>"

where <title> is a terse description of the Feature (just enough to tell what it is), <narrative section> is a succinct, natural language description of our current understanding of the Feature, including any questions or uncertainties, <shared context> is for any setup steps shared by all associated Scenarios and <scenarios> are the associated Scenarios.

A scenario is a concrete example of one element of the Feature's desired system capability. Scenarios are used by humans to explore, discover and agree on the details of what's expected to be done for the Feature. They also, along with associated test code, serve as a way to programatically confirm that the system functions as expected.

For each Feature, generate as many Scenarios as seems appropriate to fully test and implement it; err on the side of being thorough. Each Scenario should be focused on a single element of functionality, but it's fine if that "single element of functionality" requires multiple test instances, each with different data (Scenario Templates are useful for these situations).

Scenarios should be about *what* should happen and not *how* it should happen, so they should be language-agnostic and contain no expectations about implementation details.

Scenarios should be independent of the state or outcome of other scenarios.

Begin by generating Scenarios for base cases, then generate at least 2 Scenarios for what would be normal, expected behavior and normal, expected inputs (apart from the base cases), and finally generate Scenarios for edge cases, unexpected behavior and inputs, and errors. For each base case Scenario, add a @base tag. For each normal, expected Scenario add a @normal tag. For each edge case, unexpected behavior, or error Scenario add an @abnormal tag. Be thorough in providing Scenarios for Features, so that I can be confident the Features will be robust.

Regarding keywords, use "Scenario" rather than "Example", "Scenario Outline" rather than "Scenario Template", and, within Scenario Outlines, "Examples" rather than "Scenarios". Put quotation marks around step arguments that are strings, as this increases clarity. Add the @skip tag to each Scenario, so that I can test and implement them one-by-one by removing the tag from the Scenario I'm implementing.

With all the above instructions in mind, assess provided user story files and any provided feature files. Generate new Features and their Scenarios where appropriate. Where a user story's desired behavior could reasonably be part of an existing Feature, iterate on that Feature as necessary, perhaps by adding new Scenarios or adjusting existing ones. Feel free to edit any Scenarios with the @skip tag, as those have not yet been implemented. If a Scenario does not have a @skip tag, do not edit it. You are also free to edit an existing Feature's narrative section.

There should only be one Feature per feature files. All generated feature files should be named identically to the Feature's title, except the file name should be separated by underscores, and it should have the .feature extension.

* Generating step definitions
I will provide you with Gherkin feature files, specify a language and maybe suggest an organizational scheme with which to categorize Step Definitions. I may also provide a set of existing Step Definition files. Generate Step Definitions for all Features according to the relevant language-specific instructions (which will be described in a subtree below) as well as the following general instructions:

Organize Step Definitions into step files according to domain concepts (rather than coupling step definition to Features or Scenarios). For example, there might be one file of Step Definitions that has to do with user authentication and another that has to do with sanitizing inputs. If I have suggested an organizational scheme, take that into account as well.

Step Definition files should be named like <file name>_steps.<file extension>, where <file name> is a succinct, underscore-separated name that describes the domain concept relevant to the Step Definitions it contains, and <file extension> is whatever file extension the specified language requires (.py for Python, for example).

If, according to the current organizational scheme, a new step definition belongs in an existing Step Definition file, put it there. Iterate on file names and the organization of steps among them to best fit the organizational scheme. If an existing Step Definition is only used in Scenarios that have @skip tags, or is unused, feel free to edit it; otherwise don't change its content, though you may move it to a different file if it's appropriate for organization.
  
** Python step definitions
- Generate Step Definitions for pytest-bdd.
- Prefer to use target_fixture in given/when/then decorators when possible, rather than explicitly defining a fixture to store context.
- Use parsers.parse for parsing step arguments; do not use other parsers like re.
- Add type annotations to all function parameters and type hints on all functions (unless it's not possible).
- Do not use the same name for a step argument and a fixture, as this can be confusing.
- For Then steps, make sure that the names of the step arguments that represent expected results are prefixed with "expected_" and that the names of step arguments that represent actual results are prefixed with "actual_". In method signatures, prefer to order step arguments for expected results first, and step arguments for actual results next.
- When a step parameter in the feature file is delimited by quotation marks, make sure the corresponding Step Definition accounts for those quotation marks. For example, the Gherkin step 'Given the day is "<day>"' should result in the code 'parsers.parse("the day is \"{day}\"")' within the corresponding @given decorator.
- When using an empty string as a step parameter in a feature file, make sure the string is explicitly represented by ""
- Avoid using the @scenario decorator if possible; all logic should be inside Given/When/Then steps, because this is recommended in the pytest-bdd documentation.
- Use the scenarios decorator after the import statement to bind the step file to the associated feature file, for example: scenarios("my_feature_name.feature"). Assume that python knows where the features directory is, so just use the name of the file itself without a directory path.
- For step names that are not identical but mean the same thing and need identical Step Definition logic, create one step definiton and decorate it with multiple step aliases.
- File and directory titles should use underscores as spaces (rather than dashes).
- File extensions should be ".py".
- Generate test logic, but comment it out and end each Step Definition with "pass", unless it's a very simple function. This is so that I can uncomment and implement the Step Definitions one-by-one.
- Do not put docstrings or TODO comments in Step Definitions.
  
For further reference, see all content on the pytest-bdd site: https://pypi.org/project/pytest-bdd/

